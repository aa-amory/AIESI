{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AIESI.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZywuWnSGi1j",
        "outputId": "e3778831-3119-406e-fa97-a0537515849e"
      },
      "source": [
        "!git clone https://github.com/aa-amory/AIESI.git"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'AIESI'...\n",
            "remote: Enumerating objects: 8, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 267 (delta 2), reused 0 (delta 0), pack-reused 259\u001b[K\n",
            "Receiving objects: 100% (267/267), 25.98 MiB | 30.61 MiB/s, done.\n",
            "Resolving deltas: 100% (21/21), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyWX5xThdy5O"
      },
      "source": [
        "\r\n",
        "\r\n",
        "```\r\n",
        "# This is formatted as code\r\n",
        "```\r\n",
        "\r\n",
        "# PIP all required lib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgFm5iIEdZ5o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 903
        },
        "outputId": "61db50e7-8ca0-4917-e2eb-0d4b73227dc2"
      },
      "source": [
        "!pip install -U git+https://github.com/madmaze/pytesseract.git\r\n",
        "!sudo apt install tesseract-ocr\r\n",
        "!pip install colorama\r\n",
        "!pip install opencv_wrapper"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/madmaze/pytesseract.git\n",
            "  Cloning https://github.com/madmaze/pytesseract.git to /tmp/pip-req-build-r5jvkmh6\n",
            "  Running command git clone -q https://github.com/madmaze/pytesseract.git /tmp/pip-req-build-r5jvkmh6\n",
            "Requirement already satisfied, skipping upgrade: Pillow in /usr/local/lib/python3.7/dist-packages (from pytesseract==0.3.7) (7.0.0)\n",
            "Building wheels for collected packages: pytesseract\n",
            "  Building wheel for pytesseract (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytesseract: filename=pytesseract-0.3.7-py2.py3-none-any.whl size=14106 sha256=ba54975aa8848b62aa4365162c6d8023d6fc73ca5deca62383d155f8dd254f3e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-rkuizsnd/wheels/be/2a/a1/a40dbc7e579dffb2be8bbc3243c491de2d132899309f008b1f\n",
            "Successfully built pytesseract\n",
            "Installing collected packages: pytesseract\n",
            "  Found existing installation: pytesseract 0.3.7\n",
            "    Uninstalling pytesseract-0.3.7:\n",
            "      Successfully uninstalled pytesseract-0.3.7\n",
            "Successfully installed pytesseract-0.3.7\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.00~git2288-10f4998a-2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (0.4.4)\n",
            "Collecting opencv_wrapper\n",
            "  Downloading https://files.pythonhosted.org/packages/a6/35/07177ec8074623831493c793643b6ec8c444fbc0d7f73a9dfdba486ce65a/opencv-wrapper-0.2.3.tar.gz\n",
            "Collecting numpy<=1.16.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/e7/6c780e612d245cca62bc3ba8e263038f7c144a96a54f877f3714a0e8427e/numpy-1.16.2-cp37-cp37m-manylinux1_x86_64.whl (17.3MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3MB 213kB/s \n",
            "\u001b[?25hCollecting opencv-python<=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/bd/e0a4391ac105ecf73a6e14372174b05774634c7c6454e49c38750d516eee/opencv_python-4.0.0.21-cp37-cp37m-manylinux1_x86_64.whl (25.4MB)\n",
            "\u001b[K     |████████████████████████████████| 25.4MB 75.4MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: opencv-wrapper\n",
            "  Building wheel for opencv-wrapper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for opencv-wrapper: filename=opencv_wrapper-0.2.3-py2.py3-none-any.whl size=18575 sha256=6684c7cdd6aabd8af93325892fbf27e038109e6dc8ab747adc6052a02a337f28\n",
            "  Stored in directory: /root/.cache/pip/wheels/74/fc/22/03106b3bcb2516e69317562a2aa4ceb94b0d5813a448edd928\n",
            "Successfully built opencv-wrapper\n",
            "\u001b[31mERROR: umap-learn 0.5.1 has requirement numpy>=1.17, but you'll have numpy 1.16.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement numpy~=1.19.2, but you'll have numpy 1.16.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pyarrow 3.0.0 has requirement numpy>=1.16.6, but you'll have numpy 1.16.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: astropy 4.2 has requirement numpy>=1.17, but you'll have numpy 1.16.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, opencv-python, opencv-wrapper\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "Successfully installed numpy-1.16.2 opencv-python-4.0.0.21 opencv-wrapper-0.2.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbs9mVYOziyI"
      },
      "source": [
        "### Hyper- parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7x9C_ufMx9b"
      },
      "source": [
        "# Import libs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dOLid4WM4Jy"
      },
      "source": [
        "import json\r\n",
        "import os\r\n",
        "import random\r\n",
        "from os import path\r\n",
        "from string import ascii_uppercase, digits, punctuation\r\n",
        "import colorama\r\n",
        "import regex\r\n",
        "import torch\r\n",
        "from torch import nn\r\n",
        "import pytesseract\r\n",
        "import cv2\r\n",
        "import argparse\r\n",
        "import numpy as np\r\n",
        "import opencv_wrapper as cvw\r\n",
        "from skimage.filters import threshold_local"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3YGzBc9zh9g"
      },
      "source": [
        "device= 'cpu'\n",
        "hidden_size = 256\n",
        "\n",
        "device= torch.device('cpu')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NLchCHPeO89"
      },
      "source": [
        "# full code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5UecDajfpVT"
      },
      "source": [
        "VOCAB= ascii_uppercase+digits+punctuation+\" \\t\\n\"\r\n",
        "def get_acc(directory, path):\r\n",
        "    font     = cv2.FONT_HERSHEY_SIMPLEX\r\n",
        "    fontScale = 0.5\r\n",
        "    fontColor  = (255,0,0)\r\n",
        "    lineType = 1\r\n",
        "    path = directory+path\r\n",
        "    # path = args['image']\r\n",
        "    # op_path = args['output']\r\n",
        "\r\n",
        "    op_path = directory\r\n",
        "    if op_path[-1]!='/':\r\n",
        "    \top_path.append('/')\r\n",
        "\r\n",
        "\r\n",
        "    #Threshold\r\n",
        "    image = cv2.imread(path)\r\n",
        "\r\n",
        "    height,width,channel = image.shape\r\n",
        "\r\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\r\n",
        "\r\n",
        "    T = threshold_local(gray, 15, offset = 6, method = \"gaussian\") # generic, mean, median, gaussian\r\n",
        "    thresh = (gray > T).astype(\"uint8\") * 255\r\n",
        "    thresh = ~thresh\r\n",
        "\r\n",
        "    #cv2.imwrite(op_path+'threshold.png', thresh)\r\n",
        "\r\n",
        "    #Dilation\r\n",
        "    kernel =np.ones((1,1), np.uint8)\r\n",
        "    ero = cv2.erode(thresh, kernel, iterations= 1)\r\n",
        "    img_dilation = cv2.dilate(ero, kernel, iterations=1)\r\n",
        "    #cv2.imwrite(op_path+'dilated.png', img_dilation)\r\n",
        "\r\n",
        "    # Remove noise\r\n",
        "    nlabels, labels, stats, centroids = cv2.connectedComponentsWithStats(img_dilation, None, None, None, 8, cv2.CV_32S)\r\n",
        "    sizes = stats[1:, -1] #get CC_STAT_AREA component\r\n",
        "    final = np.zeros((labels.shape), np.uint8)\r\n",
        "    for i in range(0, nlabels - 1):\r\n",
        "        if sizes[i] >= 10:   #filter small dotted regions\r\n",
        "            final[labels == i + 1] = 255\r\n",
        "    #cv2.imwrite(op_path+'final.png', final)\r\n",
        "    #Find contours\r\n",
        "    kern = np.ones((5,15), np.uint8)\r\n",
        "    img_dilation = cv2.dilate(final, kern, iterations = 1)\r\n",
        "    #cv2.imwrite(op_path+'contours.png', img_dilation)\r\n",
        "    contours, hierarchy = cv2.findContours(img_dilation, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\r\n",
        "    # Map contours to bounding rectangles, using bounding_rect property\r\n",
        "    rects = map(lambda c: cv2.boundingRect(c), contours)\r\n",
        "    # Sort rects by top-left x (rect.x == rect.tl.x)\r\n",
        "    sorted_rects = sorted(rects, key =lambda r: r[0])\r\n",
        "    sorted_rects = sorted(sorted_rects, key =lambda r: r[1])\r\n",
        "\r\n",
        "    tt = image.copy()\r\n",
        "    dictionary = {}\r\n",
        "    etfo=''\r\n",
        "    for i,rect in enumerate(sorted_rects):\r\n",
        "        temp_dic = {}\r\n",
        "        x,y,w,h = rect\r\n",
        "        if(w<20 or h<20):\r\n",
        "            continue\r\n",
        "        temp_dic['coords'] = [x,y,w,h]\r\n",
        "        words = []\r\n",
        "        temp = tt[y:y+h, x:x+w]\r\n",
        "        #cv2.imwrite('/content/gdrive/My Drive/ResearchPaper/AIESI_complete_pipeline/temp/'+str(i)+'.png',temp)\r\n",
        "        temp = cv2.cvtColor(temp, cv2.COLOR_BGR2RGB)\r\n",
        "        hi = pytesseract.image_to_data(temp, config=r'--psm 6')\r\n",
        "        print('--------************---pytesseract--------************------')\r\n",
        "        print(hi)\r\n",
        "        hi = hi.split()\r\n",
        "        ind = 22\r\n",
        "        while(True):\r\n",
        "            if (ind>len(hi)):\r\n",
        "                break\r\n",
        "            if(int(hi[ind])==-1):\r\n",
        "                ind+=11\r\n",
        "            else:\r\n",
        "                #cv2.putText(image,hi[ind]+','+hi[ind+1], (x,y), font, fontScale,fontColor,lineType)\r\n",
        "                tem = {}\r\n",
        "                tem['confidence'] = hi[ind]\r\n",
        "                tem['text'] = hi[ind+1]\r\n",
        "                etfo=etfo+hi[ind+1]\r\n",
        "                etfo=etfo+\" \"\r\n",
        "                x+=len(hi[ind+1])*20\r\n",
        "                ind+=12\r\n",
        "                words.append(tem)\r\n",
        "        temp_dic['words'] = words\r\n",
        "        etfo=etfo+'\\n'\r\n",
        "        #cvw.rectangle(image, rect, cvw.Color.GREEN, thickness=1)\r\n",
        "        dictionary[i] = temp_dic\r\n",
        "\r\n",
        "\r\n",
        "    cv2.imwrite(op_path+\"result.png\", image)\r\n",
        "    return json.dumps(dictionary),etfo\r\n",
        "\r\n",
        "\r\n",
        "class MyModel0(nn.Module):\r\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size):\r\n",
        "        super().__init__()\r\n",
        "        self.embed = nn.Embedding(vocab_size, embed_size)\r\n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers=2, bidirectional=True)\r\n",
        "        self.linear = nn.Linear(hidden_size * 2, 5)\r\n",
        "\r\n",
        "    def forward(self, inpt):\r\n",
        "        embedded = self.embed(inpt)\r\n",
        "        \r\n",
        "        feature, _ = self.lstm(embedded)\r\n",
        "        oupt = self.linear(feature)\r\n",
        "        return oupt\r\n",
        "\r\n",
        "def get_test_data(etfo_param):\r\n",
        "    \r\n",
        "    text = etfo_param\r\n",
        "    text_tensor = torch.zeros(len(text), 1, dtype=torch.long)\r\n",
        "    text_tensor[:, 0] = torch.LongTensor([VOCAB.find(c) for c in text])\r\n",
        "\r\n",
        "    return text_tensor.to(device)\r\n",
        "\r\n",
        "def pred_to_dict(text, pred, prob):\r\n",
        "    res = {\"company\": (\"\", 0), \"date\": (\"\", 0), \"address\": (\"\", 0), \"total\": (\"\", 0)}\r\n",
        "    keys = list(res.keys())\r\n",
        "\r\n",
        "    seps = [0] + (np.nonzero(np.diff(pred))[0] + 1).tolist() + [len(pred)]\r\n",
        "    for i in range(len(seps) - 1):\r\n",
        "        pred_class = pred[seps[i]] - 1\r\n",
        "        if pred_class == -1:\r\n",
        "            continue\r\n",
        "\r\n",
        "        new_key = keys[pred_class]\r\n",
        "        new_prob = prob[seps[i] : seps[i + 1]].max()\r\n",
        "        if new_prob > res[new_key][1]:\r\n",
        "            res[new_key] = (text[seps[i] : seps[i + 1]], new_prob)\r\n",
        "\r\n",
        "    return {k: regex.sub(r\"[\\t\\n]\", \" \", v[0].strip()) for k, v in res.items()}\r\n",
        "\r\n",
        "\r\n",
        "def test(txt_tnsr):\r\n",
        "    model = MyModel0(len(VOCAB), 16, hidden_size).to(device)\r\n",
        "    # dataset = MyDataset(None, args.device, test_path=\"/content/gdrive/My Drive/ResearchPaper/KIPE/data/test_dict.pth\")\r\n",
        "    \r\n",
        "    model.load_state_dict(torch.load(\"/content/AIESI/AIESI_using_tesseract/model.pth\"))\r\n",
        "\r\n",
        "    model.eval()\r\n",
        "    with torch.no_grad():\r\n",
        "            #oupt = model(text_tensor)\r\n",
        "            oupt = model(txt_tnsr)\r\n",
        "            prob = torch.nn.functional.softmax(oupt, dim=2)\r\n",
        "            prob, pred = torch.max(prob, dim=2)\r\n",
        "            prob = prob.squeeze().cpu().numpy()\r\n",
        "            pred = pred.squeeze().cpu().numpy()\r\n",
        "            real_text = etfo\r\n",
        "            \r\n",
        "            result = pred_to_dict(real_text, pred, prob)\r\n",
        "\r\n",
        "            with open(\"/content/AIESI/AIESI_using_tesseract/results\" + 'result.txt' + \".txt\", \"w\", encoding=\"utf-8\") as json_opened:\r\n",
        "                json.dump(result, json_opened, indent=4)\r\n",
        "\r\n",
        "            print('-------------------------------Test result----------------------------------')\r\n",
        "            print(result)\r\n",
        "            #print(key)\r\n",
        "\r\n",
        "\r\n",
        "def pre_text(img_name):\r\n",
        "  gson_data, etfo = get_acc('/content/AIESI/invoices/',img_name)\r\n",
        "  print('----------------get_acc-->gson_data ---------------------------')\r\n",
        "  print(gson_data)\r\n",
        "  print('----------------get_acc-->etfo ---------------------------')\r\n",
        "  print(etfo)\r\n",
        "\r\n",
        "  VOCAB= ascii_uppercase+digits+punctuation+\" \\t\\n\"\r\n",
        "  temp_text=''\r\n",
        "  for i in range(0,len(etfo)-1):\r\n",
        "      temp_text=temp_text+etfo[i]\r\n",
        "  etfo=temp_text\r\n",
        "  etfo= etfo.upper()\r\n",
        "  text_tensor = get_test_data(etfo)\r\n",
        "  for i in range(0,(len(text_tensor)-1)):\r\n",
        "    '''if text_tensor[i]<0 or text_tensor[i]>70:\r\n",
        "      text_tensor = torch.cat([text_tensor[0:i], text_tensor[i+1:]])\r\n",
        "    ''' \r\n",
        "    text_tensor=text_tensor[text_tensor[:, 0] > 0]\r\n",
        "    text_tensor=text_tensor[text_tensor[:, 0] < 70]\r\n",
        "  return text_tensor"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkyHV8TSIVNx"
      },
      "source": [
        "from os import walk\r\n",
        "filenames='start_itr'\r\n",
        "_, _, filenames = next(walk('/content/AIESI/invoices/'),\"itr_end\")\r\n",
        "for f in range(0,len(filenames)-1):\r\n",
        "  print('----------'+filenames[f]+'--------------')\r\n",
        "  if filenames[f]!='inv_list.txt':\r\n",
        "    img_name=filenames[f]\r\n",
        "    txt_tnsr=pre_text(img_name)\r\n",
        "    test(txt_tnsr)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}